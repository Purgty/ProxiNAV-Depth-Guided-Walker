{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b46963bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000015_jpg.rf.45cd4e1f3a8f76136cc01074dda38e99.jpg: 640x640 3 roads, 36.3ms\n",
      "image 2/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000042_jpg.rf.7f3c5d31a13fa8b504e72dd54d2554da.jpg: 640x640 4 sidewalks, 7 roads, 36.5ms\n",
      "image 3/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000049_jpg.rf.7d56336b38ddf31b11fb2b51f579e4e2.jpg: 640x640 1 sidewalk, 39.7ms\n",
      "image 4/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000054_jpg.rf.d1af98cf95e6844ce9bc18af7a5db6e7.jpg: 640x640 2 sidewalks, 38.6ms\n",
      "image 5/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000074_jpg.rf.a081398ded072355c065ca7d3c26d955.jpg: 640x640 3 sidewalks, 38.3ms\n",
      "image 6/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000084_jpg.rf.4596fedcb2ed6303d6d8d47040bddf6a.jpg: 640x640 (no detections), 34.3ms\n",
      "image 7/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000085_jpg.rf.8baeb256c54fd720ea0f896b55205204.jpg: 640x640 (no detections), 35.1ms\n",
      "image 8/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000090_jpg.rf.cff6a56ba3cb4f42a16c41d40e923f03.jpg: 640x640 2 sidewalks, 1 road, 36.0ms\n",
      "image 9/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000093_jpg.rf.a1184e1ea9311201a49f5a69d35d8832.jpg: 640x640 4 sidewalks, 38.7ms\n",
      "image 10/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000094_jpg.rf.0407e6c3fad7a6a250e5561e53d8a3af.jpg: 640x640 1 road, 38.9ms\n",
      "image 11/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000104_jpg.rf.4ab3e918189729042f17f09f919b4e13.jpg: 640x640 3 sidewalks, 1 road, 44.2ms\n",
      "image 12/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000116_jpg.rf.63afca87a2271d7829186cdd7b8876c8.jpg: 640x640 2 sidewalks, 6 roads, 41.4ms\n",
      "image 13/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000117_jpg.rf.b3458912fd511785a703f425ca5572a5.jpg: 640x640 2 sidewalks, 1 road, 46.6ms\n",
      "image 14/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000120_jpg.rf.dcc7a898d01f1a33f68e060c144028a1.jpg: 640x640 2 sidewalks, 42.6ms\n",
      "image 15/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000150_jpg.rf.817a5bf061058aeef26954c6120a7d7e.jpg: 640x640 4 sidewalks, 40.3ms\n",
      "image 16/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000164_jpg.rf.70941f9c1bf58aa77f482d6e02147d4e.jpg: 640x640 2 sidewalks, 41.5ms\n",
      "image 17/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000172_jpg.rf.aa4a53ab292fe2d0a914976ec35e89e1.jpg: 640x640 2 sidewalks, 1 road, 40.1ms\n",
      "image 18/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000179_jpg.rf.a85c4bb1410a550622ab7884a1b9a624.jpg: 640x640 1 sidewalk, 50.2ms\n",
      "image 19/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000200_jpg.rf.5415cbf06e1bdad1452a000baa24d4dc.jpg: 640x640 (no detections), 47.4ms\n",
      "image 20/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000225_jpg.rf.5cbca408a36b64ffc12032d149abd59a.jpg: 640x640 (no detections), 47.0ms\n",
      "image 21/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000226_jpg.rf.0b0e59f4ae73b3e355931c0a7074ff5f.jpg: 640x640 (no detections), 45.1ms\n",
      "image 22/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000228_jpg.rf.77feda94f08150d51ebdb1b89ce736fa.jpg: 640x640 5 sidewalks, 4 roads, 45.9ms\n",
      "image 23/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000229_jpg.rf.2f4cfa9f61ac26b805f44075ed2b0754.jpg: 640x640 (no detections), 45.1ms\n",
      "image 24/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000246_jpg.rf.ee04001e6fb8a051e4be270849a51477.jpg: 640x640 1 road, 46.4ms\n",
      "image 25/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000268_jpg.rf.6eac2cca36132cc77073a97ac230f76a.jpg: 640x640 3 sidewalks, 6 roads, 46.0ms\n",
      "image 26/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000278_jpg.rf.185fd07439c063ca033008af6c80cef8.jpg: 640x640 (no detections), 47.3ms\n",
      "image 27/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000292_jpg.rf.a28854197e1524a860eec35d5bc36c21.jpg: 640x640 1 sidewalk, 43.7ms\n",
      "image 28/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000295_jpg.rf.f69de453338fa84c565dcc4cc3a98ab7.jpg: 640x640 1 road, 48.0ms\n",
      "image 29/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000305_jpg.rf.2eda6e3a5ba206b2a2cda226673e4242.jpg: 640x640 3 sidewalks, 1 road, 45.6ms\n",
      "image 30/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000312_jpg.rf.c720221f64fa83aa7b6b8f1937045897.jpg: 640x640 6 roads, 45.3ms\n",
      "image 31/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000313_jpg.rf.3fc58112958cba26ff8a207406ee3204.jpg: 640x640 2 sidewalks, 2 roads, 45.6ms\n",
      "image 32/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000335_jpg.rf.e5d9a979c05514ec79178fb267b3869e.jpg: 640x640 1 sidewalk, 43.3ms\n",
      "image 33/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000357_jpg.rf.e5c929340ca1ef016f215b849bdb9957.jpg: 640x640 1 sidewalk, 1 road, 43.8ms\n",
      "image 34/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000361_jpg.rf.9e1f01afda16b3a4190d426d7f1937a0.jpg: 640x640 1 sidewalk, 41.2ms\n",
      "image 35/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000365_jpg.rf.472d290f9c26851b8957ae8c750121d6.jpg: 640x640 (no detections), 42.9ms\n",
      "image 36/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000373_jpg.rf.3450d0a863035490dc346405808c8b8f.jpg: 640x640 5 sidewalks, 45.9ms\n",
      "image 37/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000379_jpg.rf.22659529e77a255a2f86518ea95a7f8b.jpg: 640x640 (no detections), 45.1ms\n",
      "image 38/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000424_jpg.rf.54019328ab146253c777926db938dceb.jpg: 640x640 1 sidewalk, 1 road, 45.0ms\n",
      "image 39/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000433_jpg.rf.e84e862bdc4359d75276e89bd5d9979a.jpg: 640x640 2 sidewalks, 41.3ms\n",
      "image 40/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000440_jpg.rf.2246a1d4a513705c3bcd8cea5a8ef9dc.jpg: 640x640 5 sidewalks, 42.4ms\n",
      "image 41/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000461_jpg.rf.c01007468e6ef831ac0676a4e02429b2.jpg: 640x640 (no detections), 43.4ms\n",
      "image 42/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000475_jpg.rf.dae2d680d6ee96ed653c5166094c444e.jpg: 640x640 3 sidewalks, 46.4ms\n",
      "image 43/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000493_jpg.rf.ac6e7282d1f1b56edf85146cd785c698.jpg: 640x640 (no detections), 47.9ms\n",
      "image 44/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000495_jpg.rf.13e4b2c1bdcf6c37bbd0bdcd7e8d08c1.jpg: 640x640 2 sidewalks, 46.3ms\n",
      "image 45/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000504_jpg.rf.ecd32ebbe3dacad9ea5188ccec13e5db.jpg: 640x640 4 sidewalks, 42.7ms\n",
      "image 46/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000512_jpg.rf.aa25e582694e04fc40602c5785716526.jpg: 640x640 7 roads, 44.6ms\n",
      "image 47/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000553_jpg.rf.0956bdf132212ff0aee4cff2c27ef4ac.jpg: 640x640 1 sidewalk, 42.8ms\n",
      "image 48/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000573_jpg.rf.451a8463190009d395c3ed60a0836191.jpg: 640x640 1 road, 43.8ms\n",
      "image 49/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000588_jpg.rf.7834a6b01d2cebec87a1c8e5cb816709.jpg: 640x640 2 roads, 33.9ms\n",
      "image 50/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000617_jpg.rf.18bc8a4e255de4d77269bfc178523e71.jpg: 640x640 8 sidewalks, 2 roads, 45.9ms\n",
      "image 51/990 C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images\\10000623_jpg.rf.901c1f0f7d677880f0a92022d01315e0.jpg: 640x640 3 roads, 47.6ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(model_path)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# === Run Inference ===\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_img\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_txt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_txt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_conf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Inference complete. Results saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\ultralytics\\engine\\model.py:555\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\ultralytics\\engine\\predictor.py:227\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\utils\\_contextlib.py:57\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m             \u001b[38;5;66;03m# Pass the last request to the generator and get its response\u001b[39;00m\n\u001b[0;32m     56\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 57\u001b[0m                 response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# We let the exceptions raised above by the generator's `.throw` or\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# `.send` methods bubble up to our caller, except for StopIteration\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# The generator informed us that it is done: take whatever its\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# returned value (if any) was and indicate that we're done too\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# by returning it (see docs for python's return-statement).\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\ultralytics\\engine\\predictor.py:330\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 330\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\ultralytics\\engine\\predictor.py:182\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    177\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    178\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    181\u001b[0m )\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:641\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 641\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\ultralytics\\nn\\tasks.py:139\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\ultralytics\\nn\\tasks.py:157\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\ultralytics\\nn\\tasks.py:180\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 180\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    181\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\ultralytics\\nn\\modules\\head.py:120\u001b[0m, in \u001b[0;36mDetect.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_end2end(x)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnl):\n\u001b[1;32m--> 120\u001b[0m     x[i] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv3[i](x[i])), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:  \u001b[38;5;66;03m# Training path\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:92\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     83\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\modules\\activation.py:405\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\torch\\nn\\functional.py:2104\u001b[0m, in \u001b[0;36msilu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   2102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[0;32m   2103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m-> 2104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# === Configuration ===\n",
    "model_path = r'C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\Pavement_Dataset_Model\\train1\\weights\\best.pt'\n",
    "input_path = r'C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\WTour_Dataset\\test\\images'  # can be image, folder, or video\n",
    "output_dir = r'C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\Pavement_Model_Inference'\n",
    "save_txt = True\n",
    "save_img = True\n",
    "\n",
    "# === Load YOLO model ===\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# === Run Inference ===\n",
    "results = model.predict(\n",
    "    source=input_path,\n",
    "    save=save_img,\n",
    "    save_txt=save_txt,\n",
    "    save_conf=True,\n",
    "    project=output_dir,\n",
    "    name='exp',\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "print(f\"✅ Inference complete. Results saved to: {os.path.join(output_dir, 'exp')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91fdc5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 3500\n",
      "Train files: 2800\n",
      "Validation files: 525\n",
      "Test files: 175\n",
      "\n",
      "Copying train files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying train images/labels: 100%|██████████| 2800/2800 [00:25<00:00, 110.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying val files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying val images/labels: 100%|██████████| 525/525 [00:04<00:00, 115.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying test files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying test images/labels: 100%|██████████| 175/175 [00:01<00:00, 135.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset split complete!\n",
      "YOLO format dataset created at: C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\data\\augmented_yolo_dataset\n",
      "Configuration file generated: C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\data\\augmented_yolo_dataset\\dataset.yaml\n",
      "\n",
      "Next steps: You can now point your YOLO training script to this dataset.yaml file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_yolo_split(\n",
    "    input_base_dir, # e.g., C:\\augmented_dataset\n",
    "    output_yolo_dataset_dir, # e.g., C:\\yolo_dataset_split\n",
    "    train_ratio=0.8,\n",
    "    val_ratio=0.1,\n",
    "    test_ratio=0.1,\n",
    "    class_names=None # List of your class names, e.g., ['pavement', 'obstacle']\n",
    "):\n",
    "    \"\"\"\n",
    "    Splits a dataset (images and YOLO annotations) into train, val, and test sets\n",
    "    and organizes them in YOLO format.\n",
    "\n",
    "    Args:\n",
    "        input_base_dir (str): Path to the base directory of your combined dataset,\n",
    "                              expected to contain 'images' and 'annotations' subfolders.\n",
    "        output_yolo_dataset_dir (str): Path to the desired output directory for the YOLO split.\n",
    "        train_ratio (float): Proportion of data for the training set.\n",
    "        val_ratio (float): Proportion of data for the validation set.\n",
    "        test_ratio (float): Proportion of data for the test set.\n",
    "        class_names (list): A list of class names in order of their IDs. Required for dataset.yaml.\n",
    "    \"\"\"\n",
    "\n",
    "    if not (abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6):\n",
    "        raise ValueError(\"Train, validation, and test ratios must sum to 1.0\")\n",
    "    if class_names is None:\n",
    "        raise ValueError(\"Class names must be provided for the dataset.yaml file.\")\n",
    "\n",
    "    input_images_dir = os.path.join(input_base_dir, 'images')\n",
    "    input_annotations_dir = os.path.join(input_base_dir, 'annotations') # Use 'annotations' as per your structure\n",
    "\n",
    "    if not os.path.exists(input_images_dir):\n",
    "        print(f\"Error: Input images directory not found at {input_images_dir}\")\n",
    "        return\n",
    "    if not os.path.exists(input_annotations_dir):\n",
    "        print(f\"Error: Input annotations directory not found at {input_annotations_dir}\")\n",
    "        return\n",
    "\n",
    "    # Create output directories\n",
    "    os.makedirs(output_yolo_dataset_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_yolo_dataset_dir, 'images', 'train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_yolo_dataset_dir, 'images', 'val'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_yolo_dataset_dir, 'images', 'test'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_yolo_dataset_dir, 'labels', 'train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_yolo_dataset_dir, 'labels', 'val'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_yolo_dataset_dir, 'labels', 'test'), exist_ok=True)\n",
    "\n",
    "    image_files = [f for f in os.listdir(input_images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))]\n",
    "    random.shuffle(image_files) # Shuffle to ensure random distribution\n",
    "\n",
    "    total_files = len(image_files)\n",
    "    if total_files == 0:\n",
    "        print(f\"No image files found in {input_images_dir}. Exiting.\")\n",
    "        return\n",
    "\n",
    "    num_train = int(total_files * train_ratio)\n",
    "    num_val = int(total_files * val_ratio)\n",
    "    num_test = total_files - num_train - num_val # Remaining files go to test to handle rounding\n",
    "\n",
    "    train_files = image_files[:num_train]\n",
    "    val_files = image_files[num_train : num_train + num_val]\n",
    "    test_files = image_files[num_train + num_val :]\n",
    "\n",
    "    splits = {\n",
    "        'train': train_files,\n",
    "        'val': val_files,\n",
    "        'test': test_files\n",
    "    }\n",
    "\n",
    "    print(f\"Total files: {total_files}\")\n",
    "    print(f\"Train files: {len(train_files)}\")\n",
    "    print(f\"Validation files: {len(val_files)}\")\n",
    "    print(f\"Test files: {len(test_files)}\")\n",
    "\n",
    "    # Copy files to their respective directories\n",
    "    for split_name, file_list in splits.items():\n",
    "        print(f\"\\nCopying {split_name} files...\")\n",
    "        for img_filename in tqdm(file_list, desc=f\"Copying {split_name} images/labels\"):\n",
    "            base_name, _ = os.path.splitext(img_filename)\n",
    "            \n",
    "            # Source paths\n",
    "            src_image_path = os.path.join(input_images_dir, img_filename)\n",
    "            src_annotation_path = os.path.join(input_annotations_dir, base_name + '.txt')\n",
    "\n",
    "            # Destination paths\n",
    "            dest_image_path = os.path.join(output_yolo_dataset_dir, 'images', split_name, img_filename)\n",
    "            dest_annotation_path = os.path.join(output_yolo_dataset_dir, 'labels', split_name, base_name + '.txt')\n",
    "\n",
    "            # Copy image\n",
    "            shutil.copyfile(src_image_path, dest_image_path)\n",
    "            \n",
    "            # Copy annotation if it exists\n",
    "            if os.path.exists(src_annotation_path):\n",
    "                shutil.copyfile(src_annotation_path, dest_annotation_path)\n",
    "            else:\n",
    "                print(f\"Warning: Annotation file not found for {img_filename} at {src_annotation_path}. Skipping.\")\n",
    "\n",
    "\n",
    "    # Create dataset.yaml file\n",
    "    dataset_yaml_content = {\n",
    "        'path': os.path.abspath(output_yolo_dataset_dir), # Absolute path to the dataset root\n",
    "        'train': '../images/train',\n",
    "        'val': '../images/val',\n",
    "        'test': '../images/test', # Optional, useful for final evaluation\n",
    "        'nc': len(class_names),\n",
    "        'names': class_names\n",
    "    }\n",
    "\n",
    "    yaml_file_path = os.path.join(output_yolo_dataset_dir, 'dataset.yaml')\n",
    "    with open(yaml_file_path, 'w') as f:\n",
    "        yaml.dump(dataset_yaml_content, f, default_flow_style=False)\n",
    "\n",
    "    print(f\"\\nDataset split complete!\")\n",
    "    print(f\"YOLO format dataset created at: {output_yolo_dataset_dir}\")\n",
    "    print(f\"Configuration file generated: {yaml_file_path}\")\n",
    "    print(\"\\nNext steps: You can now point your YOLO training script to this dataset.yaml file.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- IMPORTANT: Configure your directories and classes here ---\n",
    "    \n",
    "    # This should be the base directory where your *combined* images and annotations are.\n",
    "    # If you followed the previous step, this would be your 'augmented_dataset' folder.\n",
    "    input_dataset_base = r'C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\data\\augmented_dataset_annotations' \n",
    "    \n",
    "    # This will be the new directory where the YOLO-formatted split dataset will be created.\n",
    "    output_yolo_dataset_base = r'C:\\Users\\aswin\\OneDrive\\Desktop\\Sandbox\\AudioPavementWalkerPaper\\data\\augmented_yolo_dataset'\n",
    "\n",
    "    # !!! IMPORTANT !!! Define your class names in the correct order of their IDs\n",
    "    # E.g., if class ID 0 is 'sidewalk' and ID 1 is 'road' based on your annotation files\n",
    "    my_class_names = ['pavement', 'road'] # <<< REPLACE WITH YOUR ACTUAL CLASS NAMES\n",
    "\n",
    "    # Define split ratios\n",
    "    train_ratio = 0.8\n",
    "    val_ratio = 0.15 # Using 15% for validation\n",
    "    test_ratio = 0.05 # Using 5% for testing (adjust as needed)\n",
    "\n",
    "    create_yolo_split(\n",
    "        input_dataset_base,\n",
    "        output_yolo_dataset_base,\n",
    "        train_ratio,\n",
    "        val_ratio,\n",
    "        test_ratio,\n",
    "        my_class_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c581334e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\aswin\\miniconda3\\envs\\py38\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\aswin\\.cache\\huggingface\\hub\\datasets--shawshankvkt--Walking_Tours. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 3/3 [00:00<00:00, 326.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"shawshankvkt/Walking_Tours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d8a11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image'],\n",
      "        num_rows: 3\n",
      "    })\n",
      "})\n",
      "dict_keys(['train'])\n",
      "['image']\n",
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1354x761 at 0x2AB8BB4A250>}\n"
     ]
    }
   ],
   "source": [
    "# Show dataset structure\n",
    "print(ds)\n",
    "\n",
    "# Show available splits\n",
    "print(ds.keys())\n",
    "\n",
    "# Show column names for the 'train' split (if available)\n",
    "print(ds['train'].column_names)\n",
    "\n",
    "# Display the first example from the 'train' split\n",
    "print(ds['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55f987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
